{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([], dtype='object')\n",
      "Index([], dtype='object')\n",
      "Index([], dtype='object')\n",
      "Index([], dtype='object')\n",
      "Index([], dtype='object')\n",
      "Index([], dtype='object')\n",
      "Index([], dtype='object')\n",
      "Index([], dtype='object')\n",
      "Index([], dtype='object')\n",
      "Index([], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from random import sample,seed\n",
    "\n",
    "np.random.seed(42)\n",
    "random_state = np.random.RandomState(42)\n",
    "seed(a=42)\n",
    "\n",
    "df1 = pd.read_csv('adult.csv')\n",
    "#Sampling the dataframe just because the computing time was pretty high\n",
    "df1=df1.loc[np.sort(sample(list(df1.index), 1000))]\n",
    "df2 = pd.read_csv('bands.csv')\n",
    "df2=df2.loc[np.sort(sample(list(df2.index), 200))]\n",
    "df3 = pd.read_csv('breast.csv').reset_index().drop(\"index\",axis=1)\n",
    "df4 = pd.read_csv('crx.csv')\n",
    "df5 = pd.read_csv('hepatitis.csv')\n",
    "df6 = pd.read_csv('horse-colic.csv')\n",
    "df7 = pd.read_csv('housevotes.csv').reset_index().drop(\"index\",axis=1)\n",
    "df8 = pd.read_csv('mammographic.csv')\n",
    "df9 = pd.read_csv('mushroom.csv')\n",
    "df9=df9.loc[np.sort(sample(list(df9.index), 1000))]\n",
    "df10 = pd.read_csv('wisconsin.csv')\n",
    "\n",
    "#Looking for -1 values in the vaues of the class\n",
    "DFs=[df1,df2,df3,df4,df5,df6,df7,df8,df9,df10]\n",
    "for df in DFs:\n",
    "    print(df[df==-1].any()[df[df==-1].any().values==True].index)\n",
    "#Luckily any has this little problem\n",
    "\n",
    "\n",
    "#Function to convert categorical variables to numerical using label encoding\n",
    "\n",
    "def cat_to_num(df):\n",
    "    #Expresing nans properly\n",
    "    df=df.replace('?', np.nan)\n",
    "    df=df.replace(\"<null>\",np.nan)\n",
    "    df=df.replace(\" <null>\",np.nan)\n",
    "\n",
    "    #To replace spaces from the column names\n",
    "    columns=[]\n",
    "    for string in list(df.columns):\n",
    "        columns.append(string.strip())\n",
    "    columns[-1]= \"Class\"\n",
    "    df.columns= columns\n",
    "\n",
    "    #Transform to numeric the columns that requires it\n",
    "    df=df.apply(pd.to_numeric, errors='ignore')\n",
    "    \n",
    "    \n",
    "    #List of categories variables \n",
    "    cv_df=list(df.dtypes[df.dtypes == \"object\"].index)\n",
    "    \n",
    "    #Categorical encoding to numeric \n",
    "    for name in cv_df:\n",
    "        df[name] = df[name].astype('category').cat.codes\n",
    "    \n",
    "    \n",
    "    #Recovering the nans \n",
    "    df=df.replace(-1, np.nan)\n",
    "\n",
    "    #To compute de proportion of missing values\n",
    "    #sum(df.isnull().sum())/(df.shape[0]*df.shape[1])*100\n",
    "    \n",
    "    return df\n",
    "\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.utils import check_random_state\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "#Class to impute missing values\n",
    "\n",
    "class MissingValueImputation(BaseEstimator):\n",
    "    \n",
    "    def __init__(self, method = 'mean', k = 5, \n",
    "                 random_state = None):\n",
    "        self.method = method\n",
    "        self.k = k\n",
    "        self.random_state = random_state\n",
    "        \n",
    "    def __mean_imputation(self, X):\n",
    "        self.means_ = np.nanmean(X, axis = 0)\n",
    "        return self\n",
    "    \n",
    "    def __natural_imputation(self, X, y):\n",
    "        labels = unique_labels(y)\n",
    "        for label in labels:\n",
    "            idx = y == label\n",
    "            X_tmp = X[idx]\n",
    "            mean_tmp = np.nanmean(X_tmp, axis = 0)\n",
    "            self.means_ = {'label': label,\n",
    "                           'means': mean_tmp}\n",
    "            #print(\"self\",self.means_)\n",
    "        return self\n",
    "    \n",
    "    def __k_means_imputation(self, X):\n",
    "        pass\n",
    "    \n",
    "    def __knn_imputation(self,X):\n",
    "        imputer = KNNImputer(n_neighbors=self.k)\n",
    "        self.knni_trans = imputer.fit_transform(X)\n",
    "        return self\n",
    "    \n",
    "    def __wknn_imputation(self,X):\n",
    "        imputer = KNNImputer(n_neighbors=self.k,weights=\"distance\")\n",
    "        self.wknni_trans = imputer.fit_transform(X)\n",
    "        return self\n",
    "    \n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        if self.method == 'mean':\n",
    "            self.__mean_imputation(X)\n",
    "        elif self.method == 'natural':\n",
    "            self.__natural_imputation(X, y)\n",
    "        elif self.method == 'knni':\n",
    "            self.__knn_imputation(X)\n",
    "        elif self.method == 'wknni':\n",
    "            self.__wknn_imputation(X)\n",
    "        elif self.method == 'kmeans':\n",
    "            self.__k_means_imputation(X)\n",
    "        else:\n",
    "            raise ValueError('Unrecognized method')\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        n_samples, n_features = X.shape\n",
    "        X_ = np.copy(X)\n",
    "        \n",
    "        if self.method == 'mean':\n",
    "            for feature_index in range(n_features):\n",
    "                idx_nan = np.isnan(X[:, feature_index])\n",
    "                X_[idx_nan, feature_index] = self.means_[feature_index]\n",
    "        elif self.method=='knni':\n",
    "            X_=self.knni_trans\n",
    "        \n",
    "        elif self.method=='wknni':\n",
    "            X_=self.wknni_trans\n",
    "                    \n",
    "        elif self.method=='kmeans': \n",
    "            self.__k_means_imputation(X)\n",
    "        \n",
    "        elif self.method == 'natural':\n",
    "            for feature_index in range(n_features):\n",
    "                idx_nan = np.isnan(X[:, feature_index])\n",
    "                X_[idx_nan, feature_index] = self.means_[\"means\"][feature_index]\n",
    "                \n",
    "        else:\n",
    "            raise ValueError('Unrecognized method')\n",
    "            \n",
    "        return X_  \n",
    "    \n",
    "    def fit_transform(self, X, y):\n",
    "        return self.fit(X, y).transform(X)\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def micro_roc_auc(y_test,y_score):\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "    for i in range(n_classes):\n",
    "        fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_score[:, i])\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "    fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test.ravel(), y_score.ravel())\n",
    "    roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "    return roc_auc[\"micro\"]\n",
    "\n",
    "def classification(X,y,X_train,y_train,X_test,y_test,clf):\n",
    "    classes=list(set(y))\n",
    "    if len(classes) == 2:\n",
    "        classifier = clf\n",
    "        y_score = classifier.fit(X_train, y_train).predict(X_test)\n",
    "        roc_score=roc_auc_score(y_test, y_score)\n",
    "    #Multilabel classification, this is a prototipe, there are some issues that can be fixed in the future\n",
    "    #in this case, I choose only binary clasification datasets\n",
    "    else:\n",
    "        print(\"Not binary\")\n",
    "        y = label_binarize(y, classes=classes)    \n",
    "        n_classes = y.shape[1]\n",
    "\n",
    "        random_state = np.random.RandomState(0)\n",
    "        n_samples, n_features = X.shape\n",
    "\n",
    "        classifier = OneVsRestClassifier(clf)\n",
    "        y_score = classifier.fit(X_train, y_train).decision_function(X_test)\n",
    "        \n",
    "        roc_score=micro_roc_auc(y_test,y_score)\n",
    "    \n",
    "    return roc_score\n",
    "\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "def roc_scores_rsfk(X,y):\n",
    "    rskf = RepeatedStratifiedKFold(n_splits=2, n_repeats=10)\n",
    "    roc_scores1,roc_scores2,roc_scores3=[],[],[]\n",
    "    for train_index, test_index in rskf.split(X, y):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        #Classifiers\n",
    "        clf1 = KNeighborsClassifier(4)\n",
    "        clf2 = MLPClassifier(alpha=0.001, max_iter=1000)\n",
    "        clf3 = SVC(kernel='linear', probability=True,max_iter=1000)\n",
    "        roc_scores1.append(classification(X,y,X_train,y_train,X_test,y_test,clf1))\n",
    "        roc_scores2.append(classification(X,y,X_train,y_train,X_test,y_test,clf2))\n",
    "        roc_scores3.append(classification(X,y,X_train,y_train,X_test,y_test,clf3))\n",
    "        roc_scores = np.array([roc_scores1,roc_scores2,roc_scores3]).T\n",
    "    #return np.mean(roc_scores)\n",
    "    return roc_scores\n",
    "\n",
    "#This block of code calls all the functions and make the analisis\n",
    "\n",
    "Mean_Roc_Scores=[]\n",
    "DFs=[df1,df2,df3,df4,df5,df6,df7,df8,df9,df10]\n",
    "\n",
    "for df in DFs:\n",
    "    df = cat_to_num(df)\n",
    "    X = df.drop('Class', 1).to_numpy()\n",
    "    y = df['Class']\n",
    "    methods=[\"mean\",\"knni\",\"wknni\",\"natural\"]\n",
    "    for method in methods:\n",
    "        imputer = MissingValueImputation(method = method)\n",
    "        X_transformed = imputer.fit_transform(X, y)\n",
    "        mean_roc_scores=np.mean(roc_scores_rsfk(X_transformed,y),axis=0)\n",
    "        Mean_Roc_Scores = np.append(Mean_Roc_Scores, mean_roc_scores, axis=0)\n",
    "    print(Mean_Roc_Scores)\n",
    "\n",
    "Mean_Roc_Scores=np.around(Mean_Roc_Scores.reshape(40, 3),4)\n",
    "\n",
    "#Creating a DF with all the information\n",
    "methods_str = [\"Mean\", \"Knn\", \"WKnn\", \"Natural\"]*10\n",
    "db_names=[\"Adults\"]*4 + [\"Bands\"]*4 + [\"Breast\"]*4 + [\"CRX\"]*4 +[\"Hepatitis\"]*4 + [\"Horse Colic\"]*4 + [\"House votes\"]*4 + [\"Mammographic\"]*4 + [\"Mushroom\"]*4 + [\"Wisconsin\"]*4 \n",
    "df_ROCs = pd.DataFrame({\"Inputation method / Classificator\": methods_str,'KNN': Mean_Roc_Scores[:, 0],\n",
    "                        'Neural Nets': Mean_Roc_Scores[:, 1],'Support Vector': Mean_Roc_Scores[:, 2],\"Data Base\": db_names})\n",
    "\n",
    "\n",
    "print(df_ROCs)\n",
    "# To print the latex table\n",
    "print(df_ROCs.to_latex(index=False))\n",
    "\n",
    "#This insctruction find inputation method with the highest ROC area that are the best inputation method\n",
    "print(df_ROCs.groupby(['Data Base']).max().to_latex(index=False))\n",
    "# To print the latex table\n",
    "print(df_ROCs.groupby(['Data Base']).max().to_latex(index=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
